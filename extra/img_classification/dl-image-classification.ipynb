{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac7be8d",
   "metadata": {},
   "source": [
    "# Klassifikation von Bildern mit Deep Learning\n",
    "\n",
    "_Philipp Rapp_\n",
    "\n",
    "FOM Mechatronik Vorlesung 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cea664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsere Standard Pakete\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fortschrittsbalken\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Funktionen und Klassen fuer die Layers (Schichten) des Deep Neural Networks\n",
    "import tensorflow.nn as nn\n",
    "from tensorflow.keras.layers import Dense, MaxPool2D, Conv2D, Flatten\n",
    "\n",
    "# Datensatz\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Loss und Optimierer\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f1caf",
   "metadata": {},
   "source": [
    "## Laden des Datensatzes\n",
    "\n",
    "Wir laden die Daten von der (ehemaligen) Universitäts-Homepage von Alexander Krishevsky\n",
    "unter https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "Konkret wird die Datei https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz heruntergeladen.\n",
    "\n",
    "Die Daten werden lokal gespeichert unter `/Users/<username>/.keras/datasets` (macOS) bzw. `/home/<username>/.keras/datasets` (Linux).\n",
    "\n",
    "\n",
    "Der CIFAR-10 Datensatz besteht aus 60000 Bildern, welche wiederum jeweils einer von 10 Klassen zugeordnet sind.\n",
    "50000 Bilder sind Trainingsdaten, 10000 Bilder sind Testdaten.\n",
    "Jedes Bild hat ein Label. Dies wird benötigt, da wir _supervised learning_ betreiben.\n",
    "\n",
    "Wir bezeichnen die eigentlichen Bilddaten (die den Eingang in unser neuronales Netz bilden) mit $x$.\n",
    "Die Labels bezeichnen wir mit $y$.\n",
    "Damit kann man die Funktion des Netzes mathematisch beschreiben als $y=f(x)$.\n",
    "\n",
    "Weitere Details befinden sich im Tech Report \"Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c87118",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Klassen\n",
    "#classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "classes = ['Flugzeug', 'Auto', 'Vogel', 'Katze', 'Wild', 'Hund', 'Frosch', 'Pferd', 'Schiff', 'LKW']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir verifizieren dass wir tatsaechlich 50000 Trainings Samples und 10000 Test Samples erhalten haben.\n",
    "# Jedes Sample ist ein 32x32 Pixel Bild mit RGB Werten.\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertierung von uint8 auf float\n",
    "img = x_train[0]\n",
    "print(img[:,:,0])\n",
    "print(img[:,:,0].shape)\n",
    "print(img.dtype)\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "img = x_train[0]\n",
    "print(img[:,:,0])\n",
    "print(img[:,:,0].shape)\n",
    "print(img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung\n",
    "def imshow(img):\n",
    "    plt.imshow(img)\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(4, 20//4, idx+1, xticks=[], yticks=[])\n",
    "    imshow(x_train[idx,:,:,:])\n",
    "    ax.set_title(classes[y_train[idx].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c88d67",
   "metadata": {},
   "source": [
    "## Data Loaders\n",
    "\n",
    "Die sog. data loaders helfen uns dabei, die Daten (Input und Label) häppchenweise zu laden.\n",
    "Dabei lassen sich die Daten auch noch randomisiert durchmischen, damit wir _Stochastic Gradient Descent_ implementieren können.\n",
    "\n",
    "API Dokumentation: https://www.tensorflow.org/guide/data#basic_mechanics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d4a46",
   "metadata": {},
   "source": [
    "### Training data loader\n",
    "\n",
    "Hier wollen wir das Durchmischen haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138747a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_x = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "print(f'Length of the training data set samples is {len(dataset_train_x)}')\n",
    "\n",
    "dataset_train_y = tf.data.Dataset.from_tensor_slices(y_train.squeeze())\n",
    "print(f'Length of the training data set labels is {len(dataset_train_y)}')\n",
    "\n",
    "# Jetzt verknupfen wir die Samples und die Labels.\n",
    "# Dies ermoeglicht es uns, ueber die Trainingsdaten zu iterieren und jedes Mal\n",
    "# Eingangsdaten (Samples) mit passenden Labels zu erhalten.\n",
    "# Wichtig ist hierbei, dass dieser Schritt vor der Durchmischung (Shuffling)\n",
    "# passieren muss.\n",
    "dataset_train = tf.data.Dataset.zip((dataset_train_x, dataset_train_y))\n",
    "\n",
    "# Jetzt setzen wir die Groesse der Samples, die pro Schritt verarbeitet werden.\n",
    "# Dies ist die (Mini) Batch Size.\n",
    "batch_size = 20\n",
    "dataset_train = dataset_train.batch(batch_size)\n",
    "print(f'Length of the training data set is {len(dataset_train)} for a batch size of {batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durchmischen des Datensatzes\n",
    "dataset_train = dataset_train.shuffle(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ca189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test des Data Loaders.\n",
    "# Wir erwarten bei jedem Aufruf unterschiedliche Ergebnisse,\n",
    "# wobei Sample (Input) und Label immer zueinander passen.\n",
    "\n",
    "dataset_train_iter = iter(dataset_train)\n",
    "images, labels = next(dataset_train_iter)\n",
    "\n",
    "fig = plt.figure(figsize=(25,4))\n",
    "for idx, (image, label) in enumerate(zip(images, labels)):\n",
    "    ax = fig.add_subplot(2, 20//2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(image)\n",
    "    ax.set_title(classes[label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b0cfd",
   "metadata": {},
   "source": [
    "### Data loader fuer die Testdaten\n",
    "\n",
    "Hier brauchen wir keine Durchmischung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6995b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_x = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "dataset_test_y = tf.data.Dataset.from_tensor_slices(y_test.squeeze())\n",
    "\n",
    "dataset_test = tf.data.Dataset.zip((dataset_test_x, dataset_test_y))\n",
    "dataset_test = dataset_test.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60e0e6",
   "metadata": {},
   "source": [
    "## Definition der Architektur des Convolutional Neural Networks (CNN)\n",
    "\n",
    "API Dokumentation:\n",
    "* Allgemein\n",
    "* Conv2d function:\n",
    "* Conv2D layer:\n",
    "\n",
    "Architektur des CNNs:\n",
    "* Conv layer\n",
    "\n",
    "**Hinweis**: Die Operation in den Conv Layerns ist eine _Convolution_ (Faltung).\n",
    "Das ist die mathematische Operation, die wir in der DRT fuer die Beschreibung des Uebertragungsverhaltens eines LTI-Systems im Zeitbereich (d.h. insbesondere nicht im Frequenzbereich) kennen gelernt haben.\n",
    "\n",
    "Das LTI-System entspricht hier dem Filterkern, der die Bildverarbeitungsoperation durchfuehrt (z.B. Kantendetektion oder auch Extraktion abstrakterer Merkmale). Die Faltung ist zweidimensional, da es sich um Bilddaten handelt.\n",
    "Der Zeitbereich entspricht hier dem Pixelbereich.\n",
    "\n",
    "Wichtig ist, dass der Filterkern nicht haendisch vorgegeben wird (z.B. als Kantenfilter), sondern durch Loesung eines Optimierungsproblems berechnet (_gelernt_) wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d156ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(tf.Module):\n",
    "    \n",
    "    def __init__(self, name=None):\n",
    "        self.conv1 = Conv2D(filters=16, kernel_size=3, padding='same')\n",
    "        self.conv2 = Conv2D(filters=32, kernel_size=3, padding='same')\n",
    "        self.conv3 = Conv2D(filters=64, kernel_size=3, padding='same')\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = Dense(512)\n",
    "        self.fc2 = Dense(10)\n",
    "        \n",
    "    # Vorwaertspfad\n",
    "    def __call__(self, x):\n",
    "        # Erster Conv layer\n",
    "        x = nn.relu(self.conv1(x))\n",
    "        x = nn.max_pool2d(x, ksize=(2, 2), strides=(2, 2), padding='VALID')\n",
    "        \n",
    "        # Zweiter Conv layer\n",
    "        x = nn.relu(self.conv2(x))\n",
    "        x = nn.max_pool2d(x, ksize=(2, 2), strides=(2, 2), padding='VALID')\n",
    "        \n",
    "        \n",
    "        # Dritter Conv layer\n",
    "        x = nn.relu(self.conv3(x))\n",
    "        x = nn.max_pool2d(x, ksize=(2, 2), strides=(2, 2), padding='VALID')\n",
    "        \n",
    "        # Flatten layer.\n",
    "        # Die Features, die immer noch (wie das Bild) zweidimensional vorliegen\n",
    "        # (wenn auch mit niedrigerer Aufloesung), werden nun einen (eindimensionalen)\n",
    "        # Vektor konvertiert.\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Zwei dichte (fully-connected) layer.\n",
    "        x = nn.relu(self.fc1(x))\n",
    "        x = nn.log_softmax(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "log_ps = model(images)\n",
    "\n",
    "# Sicherstellen, dass die summe des softmax 1.0 ist,\n",
    "# da es sich um Wahrscheinlichkeiten handelt.\n",
    "# ps ... probabilities\n",
    "ps = tf.exp(log_ps)\n",
    "print(np.sum(ps, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4285b3",
   "metadata": {},
   "source": [
    "## Testen des _untrainierten_ Netzwerkes\n",
    "\n",
    "Wir erwarten, dass das untrainierte Netz in ca. 10% der Faelle ein Bild richtig klassifiziert.\n",
    "Dies ist die Erfolgsquote bei Raten, da es 10 Klassen gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrekt klassifizierte Bilder.\n",
    "correctly_classified = 0\n",
    "total_samples = 0\n",
    "\n",
    "for images, labels in dataset_test:\n",
    "    log_ps = model(images)\n",
    "    # Praedizierte Klasse\n",
    "    pred = np.argmax(log_ps, axis=1)\n",
    "    correctly_classified += np.sum(pred == labels.numpy())\n",
    "    total_samples += len(labels)\n",
    "\n",
    "print(f'Gesamtanzahl an Samples: {total_samples}')\n",
    "print(f'Korrekt klassifizierte Samples: {correctly_classified}')\n",
    "print(f'Accuracy: {correctly_classified / total_samples * 100} Prozent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02ffa5",
   "metadata": {},
   "source": [
    "## Definition des Optimierers und der Kostenfunktion (Loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CategoricalCrossentropy()\n",
    "optimizer = SGD(lr=0.003)\n",
    "\n",
    "def loss(model, x_input, y_labels):\n",
    "    log_ps = model(x_input)\n",
    "    ps = tf.exp(log_ps)\n",
    "    return criterion(y_true=tf.one_hot(y_labels, len(classes)), y_pred=ps)\n",
    "\n",
    "def train_step(model, x_input, y_labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, x_input, y_labels)\n",
    "    # Berechnung des Gradienten (das ist die Jacobi-Matrix des Losses\n",
    "    # bzgl. der Parameter oder Gewichte des Netzes).\n",
    "    gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss_value\n",
    "\n",
    "# print(loss(model, images, labels))\n",
    "# train_step(model, images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b9243",
   "metadata": {},
   "source": [
    "## Trainieren des Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dc134",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "\n",
    "print(f'Trainiere fuer {n_epochs} Epochen')\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    print(f'Epoche {epoch}')\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data, target in tqdm(dataset_train):\n",
    "        train_loss += train_step(model, data, target)\n",
    "        \n",
    "    train_loss /= len(dataset_train) * batch_size\n",
    "    \n",
    "    print(f'Training loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1609c790",
   "metadata": {},
   "source": [
    "## Test des _trainierten_ Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrekt klassifizierte Bilder.\n",
    "correctly_classified = 0\n",
    "total_samples = 0\n",
    "\n",
    "for images, labels in dataset_test:\n",
    "    log_ps = model(images)\n",
    "    # Praedizierte Klasse\n",
    "    pred = np.argmax(log_ps, axis=1)\n",
    "    correctly_classified += np.sum(pred == labels.numpy())\n",
    "    total_samples += len(labels)\n",
    "\n",
    "print(f'Gesamtanzahl an Samples: {total_samples}')\n",
    "print(f'Korrekt klassifizierte Samples: {correctly_classified}')\n",
    "print(f'Accuracy: {correctly_classified / total_samples * 100} Prozent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8dcf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ps = model(images)\n",
    "pred = np.argmax(log_ps, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "for idx, (image, label, predicted) in enumerate(zip(images, labels, pred)):\n",
    "    ax = fig.add_subplot(4, 20//4, idx+1, xticks=[], yticks=[])\n",
    "    imshow(image)\n",
    "    col = \"green\" if predicted == label else \"red\"\n",
    "    ax.set_title(f'{classes[predicted]} ({classes[label]})', color=col, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f0419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
